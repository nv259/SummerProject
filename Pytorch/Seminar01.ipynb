{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# What is PyTorch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Warm-up: numpy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Goal:** Let's start with a problem of fitting $y = sin(x)$ with a third order polynomial.\n",
    "\n",
    "Being a third order polynomial means: $$y = ax^3 + bx^2 + cx + d$$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-math.pi, math.pi, 2000)\n",
    "y = np.sin(x)\n",
    "\n",
    "# Visualize dataset\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, a, b, c, d):\n",
    "    \"\"\" y = ax^3 + bx^2 + cx + d\n",
    "        y_pred = \"\"\"\n",
    "    # Begin code here\n",
    "\n",
    "    # End code\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, y_pred):\n",
    "    \"\"\" MSE function\n",
    "        loss = \"\"\"\n",
    "    # Begin code here\n",
    "\n",
    "    # End code\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(x, y, y_pred):\n",
    "    \"\"\" Compute gradients of a, b, c, d w.r.t loss\n",
    "        grad_a =\n",
    "        grad_b =\n",
    "        grad_c =\n",
    "        grad_d = \"\"\"\n",
    "    # Begin code here\n",
    "\n",
    "    # End code\n",
    "    return grad_a, grad_b, grad_c, grad_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "a = np.random.randn()\n",
    "b = np.random.randn()\n",
    "c = np.random.randn()\n",
    "d = np.random.randn()\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "print([a, b, c, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train through forward pass and backward pass\n",
    "for epoch in range(1000):\n",
    "    # Forward pass: Compute predicted y\n",
    "    y_pred = forward(x, a, b, c, d)\n",
    "    \n",
    "    # Compute and print loss\n",
    "    loss = compute_loss(y, y_pred)\n",
    "    if epoch % 100 == 99:\n",
    "        print(f'Epoch: {epoch}, loss: {loss}')\n",
    "\n",
    "    # Backward pass: Compute gradients (a, b, c, d)\n",
    "    grad_a, grad_b, grad_c, grad_d = backward(x, y, y_pred)\n",
    "\n",
    "    # Update weights\n",
    "    a = a - learning_rate * grad_a\n",
    "    b = b - learning_rate * grad_b\n",
    "    c = c - learning_rate * grad_c\n",
    "    d = d - learning_rate * grad_d\n",
    "\n",
    "print(f'Result: y = {a}x^3 + {b}x^2 + {c}x + {d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize input and y_pred\n",
    "y_pred = forward(x, a, b, c, d)\n",
    "plt.plot(x, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PyTorch Tensors\n",
    "the central data abstraction in PyTorch."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Tensors\n",
    "\n",
    "There are many ways to create a Tensor:\n",
    "- `torch.empty()`\n",
    "- `torch.zeros()`\n",
    "- `torch.ones()`\n",
    "- `torch.rand()`\n",
    "- `torch.tensor()`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a tensor\n",
    "x = torch.empty(3, 4)  # <-- You can change to other functions to see how it works!\n",
    "\n",
    "print(type(x))\n",
    "print(x)\n",
    "print(x.dtype)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A brief note about tensors and their number of dimensions, and terminology:\n",
    "* You will sometimes see a 1-dimensional tensor called a *vector.*\n",
    "* Likewise, a 2-dimensional tensor is often referred to as a *matrix.*\n",
    "* Anything with more than two dimensions is generally just called a tensor."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tensor will copy a new content of given data\n",
    "my_tensor = torch.tensor([[2, 10],\n",
    "                          [20, 3]])\n",
    "\n",
    "my_numpy = np.array([[2, 10],\n",
    "                     [20, 3]])\n",
    "\n",
    "my_tensor = torch.tensor(my_numpy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Types\n",
    "`dtype` argument"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Specify dtype argument at creation time\n",
    "my_tensor = torch.ones((2, 3), dtype=torch.int32)\n",
    "print(my_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Or convert exist tensor to another dtype\n",
    "my_tensor = my_tensor.to(torch.bool)\n",
    "print(my_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shapes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the shape of my_tensor\n",
    "print(my_tensor)\n",
    "print(my_tensor.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can create new tensor that has the same shape with exist ones by calling `torch.*_likes()` methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Base tensor\n",
    "my_tensor = torch.empty(3, 3, 3)\n",
    "print('Base tensor:')\n",
    "print(my_tensor)\n",
    "print(my_tensor.shape)\n",
    "\n",
    "empty_like_tensor = torch.empty_like(my_tensor)\n",
    "print('\\nEmpty tensor:')\n",
    "print(empty_like_tensor)\n",
    "print(empty_like_tensor.shape)\n",
    "\n",
    "zeros_like_tensor = torch.zeros_like(my_tensor)\n",
    "print('\\nZeros tensor:')\n",
    "print(zeros_like_tensor)\n",
    "print(zeros_like_tensor.shape)\n",
    "\n",
    "rand_like_tensor = torch.rand_like(my_tensor)\n",
    "print('\\nRand tensor:')\n",
    "print(rand_like_tensor)\n",
    "print(rand_like_tensor.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Math & Logic with PyTorch Tensors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Basic arithmetic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's start with basic operation: **Tensor with Scalar**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "zeros = torch.zeros(3, 3)\n",
    "ones = zeros + 1\n",
    "twos = ones * 2\n",
    "\n",
    "print('zeros:')\n",
    "print(zeros)\n",
    "\n",
    "print('\\nones = zeros + 1:')\n",
    "print(ones)\n",
    "\n",
    "print('\\ntwos = ones * 2')\n",
    "print(twos)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see above, arithmetic operations between tensors and scalars, such as addition, subtraction, multiplication, division, and exponentiation are **distributed over every element** of the tensor.\n",
    "\n",
    "Because the output of such operation will also be a tensor, we can chain them together with the usual operator precedence rules:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Chain the operations\n",
    "fours = ((ones * 2 + 3) ** 2 - 5) / 5\n",
    "print(fours)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You'd intuitively expect the result of the similar operations between two tensors (**Tensor with Tensor**):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "threes = zeros + ones + twos\n",
    "print('threes = zeros + ones + twos:')\n",
    "print(threes)\n",
    "\n",
    "dozens = threes * fours\n",
    "print('\\ndozens = threes * fours:')\n",
    "print(dozens)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In general cases, binary operations should be performed on tensors with similar shape.\n",
    "\n",
    "**Note: The following cell throws a run-time error. This is intentional.**\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tensor2_3 = torch.rand(2, 3)\n",
    "tensor3_2 = torch.rand(3, 2)\n",
    "\n",
    "print(tensor2_3 * tensor3_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### In Brief: Tensor Broadcasting\n",
    "\n",
    "The exception to the same-shapes rule is *tensor broadcasting*.\n",
    "\n",
    "Let's see an example:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tensor2_4 = torch.ones(2, 4)\n",
    "tensor1_4 = torch.ones(1, 4)\n",
    "\n",
    "print(tensor2_4)\n",
    "print(tensor1_4)\n",
    "\n",
    "print()\n",
    "\n",
    "print('tensor2_4 + tensor1_4:')\n",
    "print(tensor2_4 + tensor1_4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following examples honor the rules and allow broadcasting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_tensor =     torch.ones(3, 4, 5, 6)\n",
    "\n",
    "# Compare from last to first\n",
    "\n",
    "# Each dimension must be equal\n",
    "a = base_tensor * torch.rand(3, 4, 5, 6)\n",
    "print(a)\n",
    "\n",
    "# or One of the dimensions must be of size 1\n",
    "b = base_tensor * torch.rand(3, 1, 5, 6)\n",
    "print(b)\n",
    "\n",
    "# or The dimension does not exist in one of the tensors\n",
    "c = base_tensor * torch.rand(   4, 5, 6)\n",
    "print(c)\n",
    "\n",
    "# or We can combine all the rules together\n",
    "d = base_tensor * torch.rand(   4, 1, 6)\n",
    "print(d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following examples are not broadcast-able, and **will throw run-time error. This is intentional.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_tensor =     torch.ones(4, 3, 2)\n",
    "\n",
    "# dimensions must match last-to-first\n",
    "a = base_tensor * torch.rand(4, 3   )\n",
    "\n",
    "b = base_tensor * torch.rand(   2, 3)\n",
    "\n",
    "# Empty tensor\n",
    "c = base_tensor * torch.rand(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### More Math with Tensors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Common Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = torch.rand(2, 4) * 2 - 1\n",
    "print('Common functions:')\n",
    "print(torch.abs(a))\n",
    "print(torch.ceil(a))\n",
    "print(a.floor())\n",
    "print(a.clamp(-0.5, 0.5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Trigonometric functions and their inverses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "angles = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
    "\n",
    "sines = torch.sin(angles)\n",
    "inverses = torch.asin(sines)\n",
    "print('Sine and acrsine:')\n",
    "print(angles)\n",
    "print(sines)\n",
    "print(inverses)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bitwise operations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b = torch.tensor([1, 5, 11])\n",
    "c = torch.tensor([2, 7, 10])\n",
    "\n",
    "print('Bitwise XOR:')\n",
    "print(torch.bitwise_xor(b, c))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Comparisions:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = torch.tensor([[1., 2.],\n",
    "                  [3., 4.]])\n",
    "e = torch.ones(1, 2)  # many comparison ops support broadcasting!\n",
    "\n",
    "print(torch.eq(d, e))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Reductions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Reduction ops:')\n",
    "\n",
    "print(torch.max(d))\n",
    "print(torch.max(d).item())\n",
    "\n",
    "print(torch.mean(d))\n",
    "print(torch.std(d))\n",
    "print(d.prod())\n",
    "print(torch.unique(torch.tensor([1, 2, 1, 2, 1, 3])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vector and linear algebra operations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "v1 = torch.tensor([1, 0, 0])\n",
    "v2 = torch.tensor([0, 1, 0])\n",
    "m1 = torch.rand(2, 2)\n",
    "m2 = torch.tensor([[3.0, 0.0], [0.0, 3.0]])\n",
    "\n",
    "print('Vector & Matrices')\n",
    "print(torch.cross(v2, v1))\n",
    "print(m1)\n",
    "m3 = torch.matmul(m1, m2)\n",
    "print(m3)\n",
    "print(torch.svd(m3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Moving to GPU"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can check whether a GPU is available, with the `is_available()` method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('máy gêm-ming')\n",
    "    my_device = torch.device('cuda')\n",
    "else:\n",
    "    print('😏')\n",
    "    my_device = torch.device('cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can create tensors on specified hardware (CPU or GPU) by setting `device` argument by `my_device`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_tensor = torch.rand(2, 2, device=my_device)\n",
    "print(my_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    ", Or move an existing tensor living on one device to another device with the `to()` method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tensor_cpu = torch.rand(2, 2)\n",
    "tensor_gpu = tensor_cpu.to(my_device)\n",
    "\n",
    "print(tensor_cpu)\n",
    "print(tensor_gpu)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def manipulate(tensor_a, tensor_b, steps):\n",
    "    t1 = time.time()\n",
    "\n",
    "    for step in range(steps):\n",
    "        tensor_a = (tensor_a * 10) / (tensor_a + tensor_b)\n",
    "\n",
    "    t2 = time.time()\n",
    "\n",
    "    print(f'Total time: {t2-t1}')\n",
    "    # print(tensor_a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can easily see that performing ops on tensors on GPU is significantly faster than with tensors on CPU (*if u have gpu to see* 👈(ﾟヮﾟ👈))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tensor_cpu = torch.ones(1000, 1000)\n",
    "tensor_gpu = torch.ones(1000, 1000, device=my_device)\n",
    "\n",
    "manipulate(tensor_cpu, tensor_cpu + 7, steps=2000)\n",
    "manipulate(tensor_gpu, tensor_gpu + 7, steps=2000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PyTorch AutoGrad"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Simple Autograd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create an input tensor and specify `requires_grad=True`. Setting this flag means that in every computation that follows, autograd will be accumulating the history of the computation in the output tensors of that computation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = torch.linspace(0., 2. * math.pi, steps=50, requires_grad=True)\n",
    "print(a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize inputs and ideal outputs\n",
    "b = torch.sin(a)\n",
    "plt.plot(a.detach(), b.detach())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see tensor `b`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `grad_fn` let us know that `b` is calculated from a tensor by using `sin` function. When we execute the backpropagation step and compute gradients, we'll need to compute the derivative of `sin(x)` for all this tensor's inputs.\n",
    "\n",
    "Let's perform some more computations:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "c = 2 * b\n",
    "print(c)\n",
    "\n",
    "d = c + 1\n",
    "print(d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out = d.sum()\n",
    "print(out)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Backward propagation is kicked off when we call `.backward()` on the output tensor. Autograd calculates and stores the gradients of each leaf node in the parameter's`.grad` attribute"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out.backward()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(a.grad)\n",
    "\n",
    "# We'll get 2*cos(a) graph\n",
    "plt.plot(a.detach(), a.grad.detach())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(c.grad)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Practice\n",
    "\n",
    "Rebuild the warm-up model with autograd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Practice here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "# Remember they are leaf node\n",
    "a = torch.randn(1)\n",
    "b = torch.randn(1)\n",
    "c = torch.randn(1)\n",
    "d = torch.randn(1)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "print(a, b, c, d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train through forward pass and backward pass\n",
    "for epoch in range(1000):\n",
    "    # Forward pass: Compute predicted y\n",
    "    y_pred =\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss =\n",
    "    if epoch % 100 == 99:\n",
    "        print(f'Epoch: {epoch}, loss: {loss}')\n",
    "\n",
    "    # Backward pass: Compute gradients (a, b, c, d) through `loss.backward()`\n",
    "    loss.backward()\n",
    "    #\n",
    "    a = a - learning_rate *\n",
    "    b = b - learning_rate *\n",
    "    c = c - learning_rate *\n",
    "    d = d - learning_rate *\n",
    "\n",
    "print(f'Result: y = {a}x^3 + {b}x^2 + {c}x +{d}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize inputs and y_pred\n",
    "y_pred = forward(x, a, b, c, d)\n",
    "plt.plot(x, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Modelize :>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Transform tensor [x] into [[x^3, x^2, x, 1]]\n",
    "class CustomTransform(object):\n",
    "    def __call__(self, x):\n",
    "        return torch.stack([x**3, x**2, x, torch.ones_like(x)], dim=1)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    CustomTransform()\n",
    "])\n",
    "\n",
    "my_device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 1, device=my_device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = torch.squeeze(x)\n",
    "        return x\n",
    "\n",
    "# Re-initialize inputs and ideal outputs\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=my_device)\n",
    "y = torch.sin(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-31.0063,   9.8696,  -3.1416,   1.0000],\n",
      "        [-30.9133,   9.8499,  -3.1384,   1.0000],\n",
      "        [-30.8205,   9.8301,  -3.1353,   1.0000],\n",
      "        ...,\n",
      "        [ 30.8205,   9.8301,   3.1353,   1.0000],\n",
      "        [ 30.9133,   9.8499,   3.1384,   1.0000],\n",
      "        [ 31.0063,   9.8696,   3.1416,   1.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Transform tensor x\n",
    "x = transform(x)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Configure hyperparameters\n",
    "num_epoch = 1000\n",
    "learning_rate = 1e-6"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = MyModel()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss(reduction='sum')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0396, -0.4987,  0.1142, -0.1733]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.linear.weight)\n",
    "print(model.linear.weight.grad)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def train_model(num_epoch=1000, learning_rate=1e-6):\n",
    "    for epoch in range(num_epoch):\n",
    "        y_pred = model(x)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(y, y_pred)\n",
    "        loss.backward()\n",
    "\n",
    "        if epoch % 100 == 99:\n",
    "            print(f\"Epoch: {epoch + 1}, loss: {loss}\")\n",
    "            # print(f'Weights: {model.linear.weight.detach()}')\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, loss: 488.60400390625\n",
      "Epoch: 200, loss: 310.7803649902344\n",
      "Epoch: 300, loss: 200.68165588378906\n",
      "Epoch: 400, loss: 131.7010955810547\n",
      "Epoch: 500, loss: 88.03895568847656\n",
      "Epoch: 600, loss: 60.1635627746582\n",
      "Epoch: 700, loss: 42.23948287963867\n",
      "Epoch: 800, loss: 30.646852493286133\n",
      "Epoch: 900, loss: 23.113815307617188\n",
      "Epoch: 1000, loss: 18.200252532958984\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_3472\\698470422.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Visualize inputs and predicted outputs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0my_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0my_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1195\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_3472\\3981167289.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1195\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    113\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 114\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    115\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    116\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# Visualize inputs and predicted outputs\n",
    "y_pred = model(x)\n",
    "# y_pred = y_pred.cpu().data.numpy()\n",
    "# x = x.cpu().data.numpy()\n",
    "plt.plot(x[:, 2], y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x2b31dd36b88>]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x[:, 2], y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Autograd Profiler\n",
    "\n",
    "Autograd tracks every step of your computation in detail. Such a computation history, combined with timing information, would make a handy profiler - and autograd has that feature to baked in."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "    aten::div        51.32%       5.307ms        51.32%       5.307ms       5.307us      14.519ms        50.01%      14.519ms      14.519us          1000  \n",
      "    aten::mul        48.68%       5.035ms        48.68%       5.035ms       5.035us      14.513ms        49.99%      14.513ms      14.513us          1000  \n",
      "-------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 10.342ms\n",
      "Self CUDA time total: 29.032ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, requires_grad=True)\n",
    "y = torch.randn(2, 3, requires_grad=True)\n",
    "z = torch.randn(2, 3, requires_grad=True)\n",
    "\n",
    "with torch.autograd.profiler.profile(use_cuda=(my_device == torch.device('cuda'))) as prf:\n",
    "    for _ in range(1000):\n",
    "        z = (z / x) * y\n",
    "\n",
    "print(prf.key_averages().table(sort_by='self_cuda_time_total'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vector Calculus"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.1410,  1.0023, -1.7604], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we tried to call `y.backward()` now, we'd get a runtime error and a message that gradients can only be *implicitly* computed for scalar outputs. For a multi-dimensional output, autograd expects us to provide gradients for those outputs that it can multiply into Jacobian:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# This will throw an error\n",
    "y.backward()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "v = torch.tensor([1.0, 1.0, 1.0]) # stand-in for gradients\n",
    "y.backward(v)\n",
    "\n",
    "print(x.grad)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
