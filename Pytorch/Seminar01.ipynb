{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# What is PyTorch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Warm-up: numpy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Goal:** Let's start with a problem of fitting $y = sin(x)$ with a third order polynomial.\n",
    "\n",
    "Being a third order polynomial means: $$y = ax^3 + bx^2 + cx + d$$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-math.pi, math.pi, 2000)\n",
    "y = np.sin(x)\n",
    "\n",
    "# Visualize dataset\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, a, b, c, d):\n",
    "    \"\"\" y = ax^3 + bx^2 + cx + d\n",
    "        y_pred = \"\"\"\n",
    "    # Begin code here\n",
    "\n",
    "    # End code\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, y_pred):\n",
    "    \"\"\" MSE function\n",
    "        loss = \"\"\"\n",
    "    # Begin code here\n",
    "\n",
    "    # End code\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(x, y, y_pred):\n",
    "    \"\"\" Compute gradients of a, b, c, d w.r.t loss\n",
    "        grad_a =\n",
    "        grad_b =\n",
    "        grad_c =\n",
    "        grad_d = \"\"\"\n",
    "    # Begin code here\n",
    "\n",
    "    # End code\n",
    "    return grad_a, grad_b, grad_c, grad_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "a = np.random.randn()\n",
    "b = np.random.randn()\n",
    "c = np.random.randn()\n",
    "d = np.random.randn()\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "print([a, b, c, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train through forward pass and backward pass\n",
    "for epoch in range(1000):\n",
    "    # Forward pass: Compute predicted y\n",
    "    y_pred = forward(x, a, b, c, d)\n",
    "    \n",
    "    # Compute and print loss\n",
    "    loss = compute_loss(y, y_pred)\n",
    "    if epoch % 100 == 99:\n",
    "        print(f'Epoch: {epoch}, loss: {loss}')\n",
    "\n",
    "    # Backward pass: Compute gradients (a, b, c, d)\n",
    "    grad_a, grad_b, grad_c, grad_d = backward(x, y, y_pred)\n",
    "\n",
    "    # Update weights\n",
    "    a = a - learning_rate * grad_a\n",
    "    b = b - learning_rate * grad_b\n",
    "    c = c - learning_rate * grad_c\n",
    "    d = d - learning_rate * grad_d\n",
    "\n",
    "print(f'Result: y = {a}x^3 + {b}x^2 + {c}x + {d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize input and y_pred\n",
    "y_pred = forward(x, a, b, c, d)\n",
    "plt.plot(x, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PyTorch Tensors\n",
    "the central data abstraction in PyTorch."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Tensors\n",
    "\n",
    "There are many ways to create a Tensor:\n",
    "- `torch.empty()`\n",
    "- `torch.zeros()`\n",
    "- `torch.ones()`\n",
    "- `torch.rand()`\n",
    "- `torch.tensor()`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a tensor\n",
    "x = torch.empty(3, 4)  # <-- You can change to other functions to see how it works!\n",
    "\n",
    "print(type(x))\n",
    "print(x)\n",
    "print(x.dtype)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A brief note about tensors and their number of dimensions, and terminology:\n",
    "* You will sometimes see a 1-dimensional tensor called a *vector.*\n",
    "* Likewise, a 2-dimensional tensor is often referred to as a *matrix.*\n",
    "* Anything with more than two dimensions is generally just called a tensor."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tensor will copy a new content of given data\n",
    "my_tensor = torch.tensor([[2, 10],\n",
    "                          [20, 3]])\n",
    "\n",
    "my_numpy = np.array([[2, 10],\n",
    "                     [20, 3]])\n",
    "\n",
    "my_tensor = torch.tensor(my_numpy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Types\n",
    "`dtype` argument"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Specify dtype argument at creation time\n",
    "my_tensor = torch.ones((2, 3), dtype=torch.int32)\n",
    "print(my_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Or convert exist tensor to another dtype\n",
    "my_tensor = my_tensor.to(torch.bool)\n",
    "print(my_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shapes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the shape of my_tensor\n",
    "print(my_tensor)\n",
    "print(my_tensor.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can create new tensor that has the same shape with exist ones by calling `torch.*_likes()` methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Base tensor\n",
    "my_tensor = torch.empty(3, 3, 3)\n",
    "print('Base tensor:')\n",
    "print(my_tensor)\n",
    "print(my_tensor.shape)\n",
    "\n",
    "empty_like_tensor = torch.empty_like(my_tensor)\n",
    "print('\\nEmpty tensor:')\n",
    "print(empty_like_tensor)\n",
    "print(empty_like_tensor.shape)\n",
    "\n",
    "zeros_like_tensor = torch.zeros_like(my_tensor)\n",
    "print('\\nZeros tensor:')\n",
    "print(zeros_like_tensor)\n",
    "print(zeros_like_tensor.shape)\n",
    "\n",
    "rand_like_tensor = torch.rand_like(my_tensor)\n",
    "print('\\nRand tensor:')\n",
    "print(rand_like_tensor)\n",
    "print(rand_like_tensor.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Math & Logic with PyTorch Tensors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Basic arithmetic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's start with basic operation: **Tensor with Scalar**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "zeros = torch.zeros(3, 3)\n",
    "ones = zeros + 1\n",
    "twos = ones * 2\n",
    "\n",
    "print('zeros:')\n",
    "print(zeros)\n",
    "\n",
    "print('\\nones = zeros + 1:')\n",
    "print(ones)\n",
    "\n",
    "print('\\ntwos = ones * 2')\n",
    "print(twos)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see above, arithmetic operations between tensors and scalars, such as addition, subtraction, multiplication, division, and exponentiation are **distributed over every element** of the tensor.\n",
    "\n",
    "Because the output of such operation will also be a tensor, we can chain them together with the usual operator precedence rules:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Chain the operations\n",
    "fours = ((ones * 2 + 3) ** 2 - 5) / 5\n",
    "print(fours)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You'd intuitively expect the result of the similar operations between two tensors (**Tensor with Tensor**):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "threes = zeros + ones + twos\n",
    "print('threes = zeros + ones + twos:')\n",
    "print(threes)\n",
    "\n",
    "dozens = threes * fours\n",
    "print('\\ndozens = threes * fours:')\n",
    "print(dozens)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In general cases, binary operations should be performed on tensors with similar shape.\n",
    "\n",
    "**Note: The following cell throws a run-time error. This is intentional.**\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tensor2_3 = torch.rand(2, 3)\n",
    "tensor3_2 = torch.rand(3, 2)\n",
    "\n",
    "print(tensor2_3 * tensor3_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### In Brief: Tensor Broadcasting\n",
    "\n",
    "The exception to the same-shapes rule is *tensor broadcasting*.\n",
    "\n",
    "Let's see an example:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tensor2_4 = torch.ones(2, 4)\n",
    "tensor1_4 = torch.ones(1, 4)\n",
    "\n",
    "print(tensor2_4)\n",
    "print(tensor1_4)\n",
    "\n",
    "print()\n",
    "\n",
    "print('tensor2_4 + tensor1_4:')\n",
    "print(tensor2_4 + tensor1_4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following examples honor the rules and allow broadcasting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_tensor =     torch.ones(3, 4, 5, 6)\n",
    "\n",
    "# Compare from last to first\n",
    "\n",
    "# Each dimension must be equal\n",
    "a = base_tensor * torch.rand(3, 4, 5, 6)\n",
    "print(a)\n",
    "\n",
    "# or One of the dimensions must be of size 1\n",
    "b = base_tensor * torch.rand(3, 1, 5, 6)\n",
    "print(b)\n",
    "\n",
    "# or The dimension does not exist in one of the tensors\n",
    "c = base_tensor * torch.rand(   4, 5, 6)\n",
    "print(c)\n",
    "\n",
    "# or We can combine all the rules together\n",
    "d = base_tensor * torch.rand(   4, 1, 6)\n",
    "print(d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following examples are not broadcast-able, and **will throw run-time error. This is intentional.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_tensor =     torch.ones(4, 3, 2)\n",
    "\n",
    "# dimensions must match last-to-first\n",
    "a = base_tensor * torch.rand(4, 3   )\n",
    "\n",
    "b = base_tensor * torch.rand(   2, 3)\n",
    "\n",
    "# Empty tensor\n",
    "c = base_tensor * torch.rand(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### More Math with Tensors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Common Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = torch.rand(2, 4) * 2 - 1\n",
    "print('Common functions:')\n",
    "print(torch.abs(a))\n",
    "print(torch.ceil(a))\n",
    "print(a.floor())\n",
    "print(a.clamp(-0.5, 0.5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Trigonometric functions and their inverses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "angles = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
    "\n",
    "sines = torch.sin(angles)\n",
    "inverses = torch.asin(sines)\n",
    "print('Sine and acrsine:')\n",
    "print(angles)\n",
    "print(sines)\n",
    "print(inverses)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bitwise operations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b = torch.tensor([1, 5, 11])\n",
    "c = torch.tensor([2, 7, 10])\n",
    "\n",
    "print('Bitwise XOR:')\n",
    "print(torch.bitwise_xor(b, c))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Comparisions:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = torch.tensor([[1., 2.],\n",
    "                  [3., 4.]])\n",
    "e = torch.ones(1, 2)  # many comparison ops support broadcasting!\n",
    "\n",
    "print(torch.eq(d, e))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Reductions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Reduction ops:')\n",
    "\n",
    "print(torch.max(d))\n",
    "print(torch.max(d).item())\n",
    "\n",
    "print(torch.mean(d))\n",
    "print(torch.std(d))\n",
    "print(d.prod())\n",
    "print(torch.unique(torch.tensor([1, 2, 1, 2, 1, 3])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vector and linear algebra operations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "v1 = torch.tensor([1, 0, 0])\n",
    "v2 = torch.tensor([0, 1, 0])\n",
    "m1 = torch.rand(2, 2)\n",
    "m2 = torch.tensor([[3.0, 0.0], [0.0, 3.0]])\n",
    "\n",
    "print('Vector & Matrices')\n",
    "print(torch.cross(v2, v1))\n",
    "print(m1)\n",
    "m3 = torch.matmul(m1, m2)\n",
    "print(m3)\n",
    "print(torch.svd(m3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Moving to GPU"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
